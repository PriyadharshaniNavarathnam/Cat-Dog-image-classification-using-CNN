{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Extract the dataset.**"
      ],
      "metadata": {
        "id": "jbtgaaxL6IAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Assuming the uploaded file is named 'dataset.zip'\n",
        "uploaded_zip_path = '/content/dataset.zip'\n",
        "extract_path = '/content/NewDataSet'  # Path to extract the dataset\n",
        "\n",
        "# Create the extract directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(uploaded_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f'Dataset extracted to {extract_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtALZ50g5N6k",
        "outputId": "8832220e-40e8-495e-ad57-c3186511d652"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted to /content/NewDataSet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List files in the extracted directory\n",
        "extracted_files = os.listdir(extract_path)\n",
        "print(f'Extracted files: {extracted_files}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vANLIv_O6BcH",
        "outputId": "09b56a76-ac2b-4678-9e6c-37fb93df1396"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['__MACOSX', 'dataset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define paths\n",
        "test_dir = '/content/NewDataSet/dataset/test'\n",
        "train_dir = '/content/NewDataSet/dataset/train'\n",
        "temp_train_dir = '/content/NewDataSet/dataset/temp_train'\n",
        "temp_validation_dir = '/content/NewDataSet/dataset/temp_validation'\n",
        "\n",
        "# Create temporary directories for split data\n",
        "os.makedirs(temp_train_dir, exist_ok=True)\n",
        "os.makedirs(temp_validation_dir, exist_ok=True)\n",
        "\n",
        "# Function to split data into training and validation sets\n",
        "def split_data(source_dir, train_dir, val_dir, train_size=0.7):\n",
        "    for class_name in os.listdir(source_dir):\n",
        "        class_path = os.path.join(source_dir, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            images = os.listdir(class_path)\n",
        "            train_images, val_images = train_test_split(images, train_size=train_size)\n",
        "\n",
        "            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "            os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "\n",
        "            for image in train_images:\n",
        "                shutil.copy(os.path.join(class_path, image), os.path.join(train_dir, class_name, image))\n",
        "            for image in val_images:\n",
        "                shutil.copy(os.path.join(class_path, image), os.path.join(val_dir, class_name, image))\n",
        "\n",
        "# Split the test data into training and validation sets\n",
        "split_data(test_dir, temp_train_dir, temp_validation_dir, train_size=0.7)\n"
      ],
      "metadata": {
        "id": "ZT1wDgjo6C3O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q2**"
      ],
      "metadata": {
        "id": "6XBXf-qyVvqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PlrR-SYDnXd",
        "outputId": "9512efb6-5ac7-4c18-8c81-7a709b6ac0de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.3.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.3.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from wandb.integration.keras import WandbCallback"
      ],
      "metadata": {
        "id": "AaIg7rb9chhD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h54lqkPhlv5W",
        "outputId": "13a8727b-47d5-4278-ed32-b7ed52321a22"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.3.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "\n",
        "# Set WANDB_API_KEY environment variable (replace 'your_api_key' with your actual API key)\n",
        "os.environ['WANDB_API_KEY'] = '5237a13f8f1acba19960eff228299c80defa0a3d'\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.login()\n",
        "wandb.init(project=\"Q2\", entity=\"praba00021\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "vHgFqyQ2mDwb",
        "outputId": "69db3a60-ba12-4820-afce-f359e60e9d9b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpraba00021\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240528_070410-7hqkl37e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/praba00021/Q2/runs/7hqkl37e' target=\"_blank\">cosmic-snowball-8</a></strong> to <a href='https://wandb.ai/praba00021/Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/praba00021/Q2' target=\"_blank\">https://wandb.ai/praba00021/Q2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/praba00021/Q2/runs/7hqkl37e' target=\"_blank\">https://wandb.ai/praba00021/Q2/runs/7hqkl37e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/praba00021/Q2/runs/7hqkl37e?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7852eae615a0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "train_data_dir = '/content/NewDataSet/dataset/train'\n",
        "test_data_dir = '/content/NewDataSet/dataset/test'\n",
        "val_data_dir = '/content/NewDataSet/dataset/test'"
      ],
      "metadata": {
        "id": "vydRBRscoRkV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set aside 10% of the training data for hyperparameter tuning\n",
        "train_images = []\n",
        "class_labels = []\n",
        "for class_name in os.listdir(train_data_dir):\n",
        "    class_path = os.path.join(train_data_dir, class_name)\n",
        "    if os.path.isdir(class_path):  # Ensure it's a directory\n",
        "        for img in os.listdir(class_path):\n",
        "            if img != '.DS_Store':  # Ignore .DS_Store files\n",
        "                train_images.append(os.path.join(class_path, img))\n",
        "                class_labels.append(class_name)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "hyperparam_tuning_data, val_data, hyperparam_tuning_labels, val_labels = train_test_split(\n",
        "    train_images, class_labels, test_size=0.1, random_state=42, stratify=class_labels)\n"
      ],
      "metadata": {
        "id": "IqUnEyzNvIl1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move validation data to a separate directory\n",
        "os.makedirs(val_data_dir, exist_ok=True)\n",
        "\n",
        "for img_path, label in zip(val_data, val_labels):\n",
        "    class_dir = os.path.join(val_data_dir, label)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "    shutil.move(img_path, class_dir)\n",
        "\n",
        "# Prepare data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_data_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY16HMLnvNAn",
        "outputId": "29ed7f4f-ed7e-46b7-8f1c-5d1ab8befec9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 585 images belonging to 2 classes.\n",
            "Found 473 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of classes\n",
        "num_classes = len([d for d in os.listdir(train_data_dir) if os.path.isdir(os.path.join(train_data_dir, d))])\n"
      ],
      "metadata": {
        "id": "pgHWxYjowRIY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to build the model\n",
        "def build_model(input_shape, num_classes, filters_per_layer, dropout_rate, use_batch_normalization):\n",
        "    model = Sequential()\n",
        "\n",
        "    for i, filters in enumerate(filters_per_layer):\n",
        "        if i == 0:\n",
        "            model.add(Conv2D(filters, (3, 3), padding='same', input_shape=input_shape))\n",
        "        else:\n",
        "            model.add(Conv2D(filters, (3, 3), padding='same'))\n",
        "\n",
        "        if use_batch_normalization:\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        if dropout_rate:\n",
        "            model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "tdCLzT00xMVj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters to tune\n",
        "filters_per_layer_options = [\n",
        "    [32, 32, 32, 32, 32],  # Same number of filters in all layers\n",
        "    [32, 64, 128, 256, 512],  # Doubling in each subsequent layer\n",
        "    [512, 256, 128, 64, 32]  # Halving in each subsequent layer\n",
        "]\n",
        "dropout_rates = [0.2, 0.3]\n",
        "use_batch_normalization = [True, False]\n"
      ],
      "metadata": {
        "id": "rwKgXw1Rr9vC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure filters_per_layer_options, dropout_rates, use_batch_normalization, train_generator, val_generator are defined correctly\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "from wandb.integration.keras import WandbCallback\n",
        "\n",
        "# Train and evaluate models with different hyperparameter configurations\n",
        "for filters_per_layer in filters_per_layer_options:\n",
        "    for dropout_rate in dropout_rates:\n",
        "        for batch_norm in use_batch_normalization:\n",
        "            # Build model\n",
        "            model = build_model(input_shape=(64, 64, 3), num_classes=num_classes, filters_per_layer=filters_per_layer, dropout_rate=dropout_rate, use_batch_normalization=batch_norm)\n",
        "\n",
        "            # Compile model\n",
        "            model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "            # Train model\n",
        "            model.fit(train_generator, epochs=10, validation_data=val_generator, callbacks=[WandbCallback()])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipgeuss7yAFL",
        "outputId": "50884045-e6b9-4c4d-846c-af65542e1f3d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.8218 - accuracy: 0.5316"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20240528_070410-7hqkl37e/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 18s 757ms/step - loss: 0.8218 - accuracy: 0.5316 - val_loss: 0.6959 - val_accuracy: 0.4989\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.7657 - accuracy: 0.5316"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20240528_070410-7hqkl37e/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 11s 594ms/step - loss: 0.7657 - accuracy: 0.5316 - val_loss: 0.6933 - val_accuracy: 0.4989\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.7218 - accuracy: 0.5675"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20240528_070410-7hqkl37e/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 11s 583ms/step - loss: 0.7218 - accuracy: 0.5675 - val_loss: 0.6918 - val_accuracy: 0.5391\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 8s 444ms/step - loss: 0.6945 - accuracy: 0.5880 - val_loss: 0.6962 - val_accuracy: 0.4989\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 7s 356ms/step - loss: 0.6798 - accuracy: 0.6034 - val_loss: 0.6922 - val_accuracy: 0.5201\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 8s 435ms/step - loss: 0.6595 - accuracy: 0.6308 - val_loss: 0.7053 - val_accuracy: 0.4989\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 8s 422ms/step - loss: 0.6572 - accuracy: 0.6325 - val_loss: 0.6933 - val_accuracy: 0.4947\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 8s 385ms/step - loss: 0.6569 - accuracy: 0.6359 - val_loss: 0.6920 - val_accuracy: 0.4989\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 8s 432ms/step - loss: 0.6571 - accuracy: 0.6068 - val_loss: 0.7067 - val_accuracy: 0.4989\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 7s 377ms/step - loss: 0.6581 - accuracy: 0.6171 - val_loss: 0.7214 - val_accuracy: 0.4989\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 9s 322ms/step - loss: 0.7033 - accuracy: 0.4974 - val_loss: 0.6929 - val_accuracy: 0.5011\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 7s 394ms/step - loss: 0.6938 - accuracy: 0.4752 - val_loss: 0.6929 - val_accuracy: 0.5011\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 6s 288ms/step - loss: 0.6946 - accuracy: 0.4701 - val_loss: 0.6930 - val_accuracy: 0.5011\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 8s 399ms/step - loss: 0.6930 - accuracy: 0.5094 - val_loss: 0.6925 - val_accuracy: 0.5412\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 6s 285ms/step - loss: 0.6943 - accuracy: 0.4906 - val_loss: 0.6934 - val_accuracy: 0.4989\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.5043"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20240528_070410-7hqkl37e/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 10s 527ms/step - loss: 0.6928 - accuracy: 0.5043 - val_loss: 0.6912 - val_accuracy: 0.5793\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 5s 280ms/step - loss: 0.6955 - accuracy: 0.5077 - val_loss: 0.6946 - val_accuracy: 0.4989\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 7s 381ms/step - loss: 0.6938 - accuracy: 0.5009 - val_loss: 0.6934 - val_accuracy: 0.4989\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 5s 275ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.4989\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 7s 369ms/step - loss: 0.6918 - accuracy: 0.5368 - val_loss: 0.6920 - val_accuracy: 0.5645\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 11s 464ms/step - loss: 0.8871 - accuracy: 0.5043 - val_loss: 0.6930 - val_accuracy: 0.4989\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 7s 341ms/step - loss: 0.7418 - accuracy: 0.5368 - val_loss: 0.6953 - val_accuracy: 0.4989\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 9s 450ms/step - loss: 0.6992 - accuracy: 0.5487 - val_loss: 0.7220 - val_accuracy: 0.4989\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 7s 372ms/step - loss: 0.7017 - accuracy: 0.5812 - val_loss: 0.6987 - val_accuracy: 0.4989\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 8s 417ms/step - loss: 0.6939 - accuracy: 0.5932 - val_loss: 0.6944 - val_accuracy: 0.4989\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 8s 436ms/step - loss: 0.6859 - accuracy: 0.5778 - val_loss: 0.6959 - val_accuracy: 0.4989\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 8s 412ms/step - loss: 0.6890 - accuracy: 0.6000 - val_loss: 0.6964 - val_accuracy: 0.4989\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 10s 471ms/step - loss: 0.6693 - accuracy: 0.5863 - val_loss: 0.7087 - val_accuracy: 0.4989\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 8s 423ms/step - loss: 0.6715 - accuracy: 0.6068 - val_loss: 0.7251 - val_accuracy: 0.4989\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 6s 332ms/step - loss: 0.6739 - accuracy: 0.6017 - val_loss: 0.7489 - val_accuracy: 0.4989\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 9s 404ms/step - loss: 0.7040 - accuracy: 0.5094 - val_loss: 0.6933 - val_accuracy: 0.4630\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 5s 279ms/step - loss: 0.6936 - accuracy: 0.4991 - val_loss: 0.6928 - val_accuracy: 0.5074\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 7s 371ms/step - loss: 0.6938 - accuracy: 0.4855 - val_loss: 0.6932 - val_accuracy: 0.4989\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 6s 290ms/step - loss: 0.6961 - accuracy: 0.5060 - val_loss: 0.6927 - val_accuracy: 0.5011\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 7s 356ms/step - loss: 0.6919 - accuracy: 0.5231 - val_loss: 0.6919 - val_accuracy: 0.5011\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 5s 273ms/step - loss: 0.6925 - accuracy: 0.5060 - val_loss: 0.6925 - val_accuracy: 0.4989\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 7s 373ms/step - loss: 0.6942 - accuracy: 0.5060 - val_loss: 0.6929 - val_accuracy: 0.4989\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5043"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20240528_070410-7hqkl37e/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 8s 417ms/step - loss: 0.6918 - accuracy: 0.5043 - val_loss: 0.6901 - val_accuracy: 0.6321\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 7s 375ms/step - loss: 0.6940 - accuracy: 0.5214 - val_loss: 0.6945 - val_accuracy: 0.4989\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 5s 267ms/step - loss: 0.6948 - accuracy: 0.5009 - val_loss: 0.6938 - val_accuracy: 0.4989\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 20s 808ms/step - loss: 3.2618 - accuracy: 0.5060 - val_loss: 0.8940 - val_accuracy: 0.5011\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 15s 783ms/step - loss: 0.7092 - accuracy: 0.5179 - val_loss: 0.6959 - val_accuracy: 0.5095\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 15s 780ms/step - loss: 0.7039 - accuracy: 0.5128 - val_loss: 0.6941 - val_accuracy: 0.4989\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 15s 782ms/step - loss: 0.7084 - accuracy: 0.5333 - val_loss: 0.7000 - val_accuracy: 0.4989\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 15s 771ms/step - loss: 0.7020 - accuracy: 0.5538 - val_loss: 0.6940 - val_accuracy: 0.5011\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 15s 774ms/step - loss: 0.6711 - accuracy: 0.5726 - val_loss: 0.7130 - val_accuracy: 0.4989\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 15s 828ms/step - loss: 0.6655 - accuracy: 0.6068 - val_loss: 0.7204 - val_accuracy: 0.4989\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 15s 813ms/step - loss: 0.6635 - accuracy: 0.6051 - val_loss: 0.7477 - val_accuracy: 0.4989\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 15s 774ms/step - loss: 0.6392 - accuracy: 0.6564 - val_loss: 0.7445 - val_accuracy: 0.4989\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 15s 788ms/step - loss: 0.6391 - accuracy: 0.6359 - val_loss: 0.8209 - val_accuracy: 0.4989\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 15s 693ms/step - loss: 0.7524 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.4989\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 13s 680ms/step - loss: 0.6940 - accuracy: 0.4786 - val_loss: 0.6931 - val_accuracy: 0.5011\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 13s 694ms/step - loss: 0.6933 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5011\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 13s 691ms/step - loss: 0.6931 - accuracy: 0.4991 - val_loss: 0.6930 - val_accuracy: 0.5011\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 13s 691ms/step - loss: 0.6929 - accuracy: 0.4991 - val_loss: 0.6919 - val_accuracy: 0.5920\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 13s 671ms/step - loss: 0.6914 - accuracy: 0.5487 - val_loss: 0.6911 - val_accuracy: 0.5708\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.5179"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20240528_070410-7hqkl37e/files/model-best)... Done. 0.2s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 15s 809ms/step - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6857 - val_accuracy: 0.5835\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6823 - accuracy: 0.5880"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20240528_070410-7hqkl37e/files/model-best)... Done. 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 16s 815ms/step - loss: 0.6823 - accuracy: 0.5880 - val_loss: 0.6726 - val_accuracy: 0.5433\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 12s 623ms/step - loss: 0.6845 - accuracy: 0.5504 - val_loss: 0.6845 - val_accuracy: 0.5518\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 13s 675ms/step - loss: 0.6890 - accuracy: 0.5231 - val_loss: 0.6753 - val_accuracy: 0.5560\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 20s 839ms/step - loss: 2.5580 - accuracy: 0.5043 - val_loss: 0.6961 - val_accuracy: 0.4989\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 15s 778ms/step - loss: 0.6783 - accuracy: 0.5846 - val_loss: 0.7051 - val_accuracy: 0.4989\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 0.6673 - accuracy: 0.6308 - val_loss: 0.7393 - val_accuracy: 0.4989\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 15s 834ms/step - loss: 0.6694 - accuracy: 0.6137 - val_loss: 0.7082 - val_accuracy: 0.4989\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 15s 787ms/step - loss: 0.6494 - accuracy: 0.6205 - val_loss: 0.8652 - val_accuracy: 0.4989\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 15s 787ms/step - loss: 0.6577 - accuracy: 0.6427 - val_loss: 0.7897 - val_accuracy: 0.4989\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 15s 789ms/step - loss: 0.6531 - accuracy: 0.6342 - val_loss: 0.8296 - val_accuracy: 0.4989\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 16s 827ms/step - loss: 0.6370 - accuracy: 0.6462 - val_loss: 0.7954 - val_accuracy: 0.4989\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 15s 775ms/step - loss: 0.6277 - accuracy: 0.6479 - val_loss: 0.8757 - val_accuracy: 0.4989\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 16s 822ms/step - loss: 0.6475 - accuracy: 0.6410 - val_loss: 0.7774 - val_accuracy: 0.4989\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 14s 668ms/step - loss: 0.7249 - accuracy: 0.4632 - val_loss: 0.6931 - val_accuracy: 0.5011\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 12s 654ms/step - loss: 0.6933 - accuracy: 0.5060 - val_loss: 0.6931 - val_accuracy: 0.5011\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 13s 665ms/step - loss: 0.6931 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.4989\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 14s 768ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6932 - val_accuracy: 0.4989\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 13s 676ms/step - loss: 0.6933 - accuracy: 0.4991 - val_loss: 0.6929 - val_accuracy: 0.5159\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 15s 781ms/step - loss: 0.6935 - accuracy: 0.5111 - val_loss: 0.6914 - val_accuracy: 0.5328\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 13s 679ms/step - loss: 0.6923 - accuracy: 0.5248 - val_loss: 0.6909 - val_accuracy: 0.6068\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 14s 768ms/step - loss: 0.6948 - accuracy: 0.4957 - val_loss: 0.6930 - val_accuracy: 0.4989\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 13s 687ms/step - loss: 0.6974 - accuracy: 0.5350 - val_loss: 0.6941 - val_accuracy: 0.4989\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 14s 766ms/step - loss: 0.6942 - accuracy: 0.5009 - val_loss: 0.6933 - val_accuracy: 0.4989\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 183s 10s/step - loss: 0.7414 - accuracy: 0.5692 - val_loss: 0.9529 - val_accuracy: 0.4989\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 174s 9s/step - loss: 0.7005 - accuracy: 0.5812 - val_loss: 0.7539 - val_accuracy: 0.4989\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 185s 10s/step - loss: 0.7319 - accuracy: 0.5812 - val_loss: 0.6924 - val_accuracy: 0.5307\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 182s 10s/step - loss: 0.6978 - accuracy: 0.5983 - val_loss: 0.6990 - val_accuracy: 0.4989\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 176s 9s/step - loss: 0.6796 - accuracy: 0.6239 - val_loss: 0.7124 - val_accuracy: 0.4989\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 176s 9s/step - loss: 0.6742 - accuracy: 0.5949 - val_loss: 0.6887 - val_accuracy: 0.5433\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 182s 10s/step - loss: 0.6471 - accuracy: 0.6496 - val_loss: 0.7353 - val_accuracy: 0.4989\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 174s 9s/step - loss: 0.6382 - accuracy: 0.6410 - val_loss: 0.7288 - val_accuracy: 0.4989\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 177s 9s/step - loss: 0.6246 - accuracy: 0.6513 - val_loss: 0.7808 - val_accuracy: 0.4989\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 177s 9s/step - loss: 0.6305 - accuracy: 0.6325 - val_loss: 0.7372 - val_accuracy: 0.4989\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 146s 8s/step - loss: 0.7271 - accuracy: 0.4974 - val_loss: 0.6930 - val_accuracy: 0.5011\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 142s 8s/step - loss: 0.6941 - accuracy: 0.4701 - val_loss: 0.6929 - val_accuracy: 0.5053\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 140s 8s/step - loss: 0.6934 - accuracy: 0.5060 - val_loss: 0.6929 - val_accuracy: 0.5011\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 140s 7s/step - loss: 0.6944 - accuracy: 0.4889 - val_loss: 0.6936 - val_accuracy: 0.4989\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 154s 8s/step - loss: 0.6936 - accuracy: 0.4923 - val_loss: 0.6922 - val_accuracy: 0.5032\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 140s 7s/step - loss: 0.6932 - accuracy: 0.5026 - val_loss: 0.6912 - val_accuracy: 0.5793\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 135s 7s/step - loss: 0.6925 - accuracy: 0.4991 - val_loss: 0.6888 - val_accuracy: 0.5624\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 138s 7s/step - loss: 0.6921 - accuracy: 0.5197 - val_loss: 0.6911 - val_accuracy: 0.5856\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 138s 7s/step - loss: 0.6908 - accuracy: 0.5453 - val_loss: 0.6912 - val_accuracy: 0.5074\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 154s 8s/step - loss: 0.6947 - accuracy: 0.5009 - val_loss: 0.6940 - val_accuracy: 0.4989\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 175s 9s/step - loss: 0.7897 - accuracy: 0.5214 - val_loss: 0.7022 - val_accuracy: 0.5032\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 173s 9s/step - loss: 0.7538 - accuracy: 0.5350 - val_loss: 0.7028 - val_accuracy: 0.4968\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 177s 9s/step - loss: 0.7312 - accuracy: 0.5350 - val_loss: 0.7838 - val_accuracy: 0.4989\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 173s 9s/step - loss: 0.7167 - accuracy: 0.5744 - val_loss: 1.0544 - val_accuracy: 0.4989\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 176s 9s/step - loss: 0.7036 - accuracy: 0.5675 - val_loss: 0.9654 - val_accuracy: 0.4989\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 175s 9s/step - loss: 0.6518 - accuracy: 0.6222 - val_loss: 1.0461 - val_accuracy: 0.4989\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 174s 9s/step - loss: 0.6762 - accuracy: 0.6068 - val_loss: 0.9963 - val_accuracy: 0.4989\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 175s 9s/step - loss: 0.6884 - accuracy: 0.5949 - val_loss: 1.0194 - val_accuracy: 0.4989\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 188s 10s/step - loss: 0.6509 - accuracy: 0.6427 - val_loss: 1.0810 - val_accuracy: 0.4989\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 186s 10s/step - loss: 0.6622 - accuracy: 0.6342 - val_loss: 1.0783 - val_accuracy: 0.4989\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 144s 8s/step - loss: 0.7074 - accuracy: 0.4889 - val_loss: 0.6950 - val_accuracy: 0.4989\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 140s 7s/step - loss: 0.6953 - accuracy: 0.5077 - val_loss: 0.6927 - val_accuracy: 0.5011\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 140s 8s/step - loss: 0.6925 - accuracy: 0.5248 - val_loss: 0.6951 - val_accuracy: 0.4989\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 153s 8s/step - loss: 0.6954 - accuracy: 0.5009 - val_loss: 0.6938 - val_accuracy: 0.4989\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 134s 7s/step - loss: 0.6935 - accuracy: 0.5128 - val_loss: 0.6931 - val_accuracy: 0.4989\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 134s 7s/step - loss: 0.6938 - accuracy: 0.4786 - val_loss: 0.6930 - val_accuracy: 0.5560\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 136s 7s/step - loss: 0.6943 - accuracy: 0.4906 - val_loss: 0.6936 - val_accuracy: 0.4989\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 154s 8s/step - loss: 0.6935 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.4989\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 140s 7s/step - loss: 0.6932 - accuracy: 0.5043 - val_loss: 0.6930 - val_accuracy: 0.4968\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 140s 7s/step - loss: 0.6932 - accuracy: 0.5214 - val_loss: 0.6927 - val_accuracy: 0.5222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUtjz7eG4Bw9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}